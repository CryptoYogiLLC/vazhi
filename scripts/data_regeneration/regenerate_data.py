#!/usr/bin/env python3
"""
VAZHI v0.4 - Data Regeneration Pipeline

This script helps regenerate English responses to proper Tamil.
Can work in multiple modes:
1. Export for manual regeneration (via Claude.ai)
2. Template-based semi-automatic regeneration
3. API-based regeneration (if API key available)
"""

import json
import re
from pathlib import Path
from typing import List
from templates import (
    THIRUKKURAL_AUTHORITATIVE,
    SIDDHARS_AUTHORITATIVE,
)

DATA_DIR = Path(__file__).parent.parent.parent / "data"
AUDIT_DIR = DATA_DIR / "v04" / "audit"
OUTPUT_DIR = DATA_DIR / "v04" / "regenerated"


def create_regeneration_prompt(sample: dict) -> str:
    """Create a prompt for LLM to regenerate the response in Tamil."""

    pack = sample.get("pack", "")
    instruction = sample.get("instruction", "")
    current_output = sample.get("output", "")
    category = sample.get("category", "")

    # Determine target language style
    if "panpaadu" in pack or "culture" in pack:
        lang_style = "pure Tamil (à®®à¯à®´à¯ à®¤à®®à®¿à®´à¯)"
        extra_instruction = """
IMPORTANT: For Thirukkural, use CITATION format with quotation marks:
- Put the actual kural text in quotes
- Include kural number, athikaram name
- Provide meaning (à®ªà¯Šà®°à¯à®³à¯) and explanation (à®µà®¿à®³à®•à¯à®•à®®à¯)
- DO NOT make up kurals - use only authentic Thirukkural text
"""
    elif "kaval" in pack or "security" in pack:
        lang_style = "Tanglish (natural Tamil-English mix as Tamils actually speak)"
        extra_instruction = "Use scam/cyber security terms naturally mixed with Tamil."
    else:
        lang_style = "Tamil with technical terms in bilingual format: 'English (à®¤à®®à®¿à®´à¯)' for first mention"
        extra_instruction = ""

    prompt = f"""Convert this English response to {lang_style}.

RULES:
1. Use actual Tamil words, not transliteration
2. Keep proper nouns (website URLs, act names) in English
3. Use structured format with Tamil headers
4. Keep the same information, just translate the language
5. Make it sound natural for a Tamil speaker
{extra_instruction}

QUESTION: {instruction}

CURRENT RESPONSE (mostly English):
{current_output}

PACK: {pack}
CATEGORY: {category}

Please provide the Tamil version:"""

    return prompt


def export_for_manual_regeneration(
    samples: List[dict], output_file: str, batch_size: int = 50
):
    """Export samples in a format suitable for manual regeneration via Claude.ai."""

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # Group by pack for easier processing
    by_pack = {}
    for sample in samples:
        pack = sample.get("pack", "unknown")
        if pack not in by_pack:
            by_pack[pack] = []
        by_pack[pack].append(sample)

    # Export each pack separately
    for pack, pack_samples in by_pack.items():
        pack_dir = OUTPUT_DIR / "for_manual" / pack
        pack_dir.mkdir(parents=True, exist_ok=True)

        # Split into batches
        for i in range(0, len(pack_samples), batch_size):
            batch = pack_samples[i : i + batch_size]
            batch_file = pack_dir / f"batch_{i//batch_size + 1}.json"

            # Create prompts for each sample
            batch_with_prompts = []
            for sample in batch:
                sample_copy = sample.copy()
                sample_copy["_regeneration_prompt"] = create_regeneration_prompt(sample)
                batch_with_prompts.append(sample_copy)

            with open(batch_file, "w", encoding="utf-8") as f:
                json.dump(batch_with_prompts, f, ensure_ascii=False, indent=2)

            print(f"Exported: {batch_file} ({len(batch)} samples)")

    # Create master instruction file
    instruction_file = OUTPUT_DIR / "for_manual" / "REGENERATION_INSTRUCTIONS.md"
    with open(instruction_file, "w", encoding="utf-8") as f:
        f.write(
            """# VAZHI Data Regeneration Instructions

## How to Regenerate Samples

1. Open each batch file (batch_1.json, batch_2.json, etc.)
2. For each sample, use the `_regeneration_prompt` field
3. Paste the prompt into Claude.ai or similar
4. Copy the Tamil response back to the `output` field
5. Remove the `_regeneration_prompt` field
6. Save the file

## Language Guidelines

### Pure Tamil (Culture Pack)
- Use full Tamil script
- Thirukkural must be in citation format with quotation marks
- Use authentic text only, no generation

### Tanglish (Security Pack)
- Natural mix like how Tamils actually speak
- "Scam message à®ªà®¾à®°à¯à®¤à¯à®¤à®¾ immediately block à®ªà®£à¯à®£à¯à®™à¯à®•"

### Bilingual (Other Packs)
- First mention: "Website (à®‡à®£à¯ˆà®¯à®¤à®³à®®à¯)"
- Subsequently: "à®‡à®£à¯ˆà®¯à®¤à®³à®®à¯"
- Technical terms can stay in English with Tamil explanation

## Quality Checks

After regeneration, ensure:
- [ ] Response is >60% Tamil characters
- [ ] Information is accurate (not made up)
- [ ] Thirukkural quotes are authentic
- [ ] Format is structured and readable
"""
        )
    print(f"\nCreated instructions: {instruction_file}")


def regenerate_culture_pack():
    """Special handling for Culture pack - use authoritative sources."""

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    culture_output = OUTPUT_DIR / "culture_authoritative.json"

    regenerated = []

    # Generate Thirukkural Q&As from authoritative source
    for kural_num, kural_data in THIRUKKURAL_AUTHORITATIVE.items():
        # Multiple question variations
        questions = [
            f"à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à®¿à®©à¯ à®•à¯à®±à®³à¯ {kural_num} à®Žà®©à¯à®©?",
            f"à®•à¯à®±à®³à¯ {kural_num} à®šà¯Šà®²à¯à®²à¯à®™à¯à®•",
        ]

        if kural_num == 1:
            questions.extend(
                [
                    "à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à®¿à®©à¯ à®®à¯à®¤à®²à¯ à®•à¯à®±à®³à¯ à®Žà®©à¯à®©?",
                    "Thirukkural à®®à¯à®¤à®²à¯ à®•à¯à®±à®³à¯ à®Žà®©à¯à®©?",
                    "à®…à®•à®° à®®à¯à®¤à®² à®•à¯à®±à®³à¯ à®šà¯Šà®²à¯à®²à¯à®™à¯à®•",
                    "à®•à®Ÿà®µà¯à®³à¯ à®µà®¾à®´à¯à®¤à¯à®¤à¯ à®®à¯à®¤à®²à¯ à®•à¯à®±à®³à¯",
                    "à®¤à®¿à®°à¯à®µà®³à¯à®³à¯à®µà®°à¯ à®Žà®´à¯à®¤à®¿à®¯ à®®à¯à®¤à®²à¯ à®•à¯à®±à®³à¯",
                ]
            )

        if kural_num == 10:
            questions.extend(
                [
                    "à®ªà®¿à®±à®µà®¿à®ªà¯ à®ªà¯†à®°à¯à®™à¯à®•à®Ÿà®²à¯ à®Žà®©à¯à®± à®•à¯à®±à®³à¯ à®Žà®©à¯à®©?",
                    "à®ªà®¿à®±à®µà®¿à®ªà¯ à®ªà¯†à®°à¯à®™à¯à®•à®Ÿà®²à¯ à®•à¯à®±à®³à¯ à®šà¯Šà®²à¯à®²à¯à®™à¯à®•",
                ]
            )

        answer = f"""ðŸ“– à®¤à®¿à®°à¯à®•à¯à®•à¯à®±à®³à¯ - {kural_data['athikaram']} à®…à®¤à®¿à®•à®¾à®°à®®à¯, à®•à¯à®±à®³à¯ {kural_num}:

"{kural_data['line1']}
{kural_data['line2']}"

ðŸ“œ à®ªà¯Šà®°à¯à®³à¯:
{kural_data['meaning']}

âœï¸ à®†à®šà®¿à®°à®¿à®¯à®°à¯: à®¤à®¿à®°à¯à®µà®³à¯à®³à¯à®µà®°à¯
ðŸ“š à®ªà®¾à®²à¯: {kural_data['paal']}
ðŸ“‘ à®‡à®¯à®²à¯: {kural_data['iyal']}
ðŸ“– à®…à®¤à®¿à®•à®¾à®°à®®à¯: {kural_data['athikaram']}"""

        for q in questions:
            regenerated.append(
                {
                    "instruction": q,
                    "output": answer,
                    "language": "pure_tamil",
                    "pack": "vazhi_panpaadu",
                    "category": "thirukkural_authoritative",
                    "id": f"KURAL_AUTH_{kural_num}_{len(regenerated):03d}",
                }
            )

    # Generate 18 Siddhars Q&As
    siddhars_list = "\n".join(
        [
            f"{i+1}. {s['name']} ({s['english']}) - {s['specialty']}"
            for i, s in enumerate(SIDDHARS_AUTHORITATIVE)
        ]
    )

    siddhars_answer = f"""ðŸ™ à®ªà®¤à®¿à®©à¯†à®£à¯ à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à¯ (18 Siddhars):

à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à¯ à®¤à®®à®¿à®´à®•à®¤à¯à®¤à®¿à®©à¯ à®žà®¾à®©à®¿à®•à®³à¯, à®®à®°à¯à®¤à¯à®¤à¯à®µà®°à¯à®•à®³à¯, à®¯à¯‹à®•à®¿à®•à®³à¯. à®‡à®µà®°à¯à®•à®³à¯ à®šà®¿à®¤à¯à®¤ à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à¯, à®¯à¯‹à®•à®¾, à®°à®šà®µà®¾à®¤à®®à¯, à®†à®©à¯à®®à¯€à®•à®®à¯ à®†à®•à®¿à®¯à®µà®±à¯à®±à®¿à®²à¯ à®šà®¿à®±à®¨à¯à®¤à®µà®°à¯à®•à®³à¯.

ðŸ“œ à®ªà®¤à®¿à®©à¯†à®£à¯ à®šà®¿à®¤à¯à®¤à®°à¯ à®ªà®Ÿà¯à®Ÿà®¿à®¯à®²à¯:
{siddhars_list}

ðŸ’¡ à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à®¿à®©à¯ à®ªà®™à¯à®•à®³à®¿à®ªà¯à®ªà¯:
â€¢ à®šà®¿à®¤à¯à®¤ à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à¯ - à®ªà®¾à®°à®®à¯à®ªà®°à®¿à®¯ à®®à®°à¯à®¤à¯à®¤à¯à®µ à®®à¯à®±à¯ˆ
â€¢ à®¯à¯‹à®•à®¾ & à®ªà®¿à®°à®¾à®£à®¾à®¯à®¾à®®à®®à¯ - à®‰à®Ÿà®²à¯ à®®à®±à¯à®±à¯à®®à¯ à®®à®© à®ªà®¯à®¿à®±à¯à®šà®¿
â€¢ à®°à®šà®µà®¾à®¤à®®à¯ - à®‰à®²à¯‹à®• à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à¯
â€¢ à®†à®©à¯à®®à¯€à®• à®‡à®²à®•à¯à®•à®¿à®¯à®®à¯ - à®ªà®•à¯à®¤à®¿ à®ªà®¾à®Ÿà®²à¯à®•à®³à¯, à®¤à®¤à¯à®¤à¯à®µ à®¨à¯‚à®²à¯à®•à®³à¯"""

    siddhars_questions = [
        "18 à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à¯ à®¯à®¾à®°à¯?",
        "à®ªà®¤à®¿à®©à¯†à®£à¯ à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à¯ à®ªà¯†à®¯à®°à¯ à®šà¯Šà®²à¯à®²à¯à®™à¯à®•",
        "à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à¯ à®¯à®¾à®°à¯? à®®à¯à®•à¯à®•à®¿à®¯ à®šà®¿à®¤à¯à®¤à®°à¯à®•à®³à®¿à®©à¯ à®ªà¯†à®¯à®°à¯à®•à®³à¯ à®šà¯Šà®²à¯à®²à¯à®™à¯à®•à®³à¯",
        "Tamil siddhars à®¯à®¾à®°à¯?",
        "18 siddhars list in Tamil",
    ]

    for q in siddhars_questions:
        regenerated.append(
            {
                "instruction": q,
                "output": siddhars_answer,
                "language": "pure_tamil" if "Tamil" not in q else "tanglish",
                "pack": "vazhi_panpaadu",
                "category": "siddhars_authoritative",
                "id": f"SIDD_AUTH_{len(regenerated):03d}",
            }
        )

    # Save
    with open(culture_output, "w", encoding="utf-8") as f:
        json.dump(regenerated, f, ensure_ascii=False, indent=2)

    print(f"\nGenerated {len(regenerated)} authoritative Culture samples")
    print(f"Saved: {culture_output}")

    return regenerated


def validate_regenerated_sample(sample: dict) -> dict:
    """Validate a regenerated sample."""
    output = sample.get("output", "")

    # Calculate Tamil percentage
    tamil_chars = len(re.findall(r"[\u0B80-\u0BFF]", output))
    english_chars = len(re.findall(r"[a-zA-Z]", output))
    total = tamil_chars + english_chars
    tamil_pct = (tamil_chars / total * 100) if total > 0 else 0

    # Check for structure
    has_structure = bool(re.search(r"[â€¢ðŸ“ðŸ“šðŸ”¢ðŸ“–ðŸ“œðŸ’¡âœï¸ðŸ¥âš–ï¸ðŸ›•ðŸ™]", output))

    # Check length
    is_adequate_length = len(output) >= 100

    return {
        "tamil_percentage": round(tamil_pct, 1),
        "has_structure": has_structure,
        "adequate_length": is_adequate_length,
        "valid": tamil_pct >= 50 and is_adequate_length,
    }


def run_audit_and_export():
    """Run full audit and export for regeneration."""

    # First run audit
    print("Step 1: Running audit...")
    import audit_data

    audit_data.audit_training_data()

    # Load regenerate samples
    print("\nStep 2: Loading samples that need regeneration...")
    regen_file = AUDIT_DIR / "regenerate_samples.json"
    with open(regen_file, "r", encoding="utf-8") as f:
        regen_samples = json.load(f)

    print(f"Samples needing regeneration: {len(regen_samples)}")

    # Export for manual regeneration
    print("\nStep 3: Exporting for manual regeneration...")
    export_for_manual_regeneration(regen_samples, "for_manual")

    # Generate authoritative Culture data
    print("\nStep 4: Generating authoritative Culture data...")
    regenerate_culture_pack()

    print("\n" + "=" * 60)
    print("EXPORT COMPLETE")
    print("=" * 60)
    print("\nNext steps:")
    print(f"1. Check {OUTPUT_DIR / 'for_manual'} for batch files")
    print("2. Use Claude.ai to regenerate each batch")
    print("3. Run validation after regeneration")


if __name__ == "__main__":
    print("VAZHI v0.4 - Data Regeneration Pipeline")
    print("=" * 60)
    run_audit_and_export()
