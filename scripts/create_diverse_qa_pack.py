#!/usr/bin/env python3
"""
Create Diverse QA Pack from AI4Bharat IndicAlign Dataset
=========================================================

This script extracts diverse Tamil QA samples from IndicAlign to rebalance
our Thirukkural-heavy training dataset.

Target: 800-1500 diverse samples covering:
- General knowledge QA
- How-to instructions (WikiHow)
- Conversational Tamil
- Short factual answers

Source: https://huggingface.co/datasets/ai4bharat/indic-align
"""

import json
import random
import re
from pathlib import Path
from datasets import load_dataset
from tqdm import tqdm

# Output directory
OUTPUT_DIR = (
    Path(__file__).parent.parent / "data" / "tamil_foundation" / "diverse_qa_pack"
)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Random seed for reproducibility
random.seed(42)


def clean_text(text: str) -> str:
    """Clean and normalize Tamil text."""
    if not text or not isinstance(text, str):
        return ""
    # Remove excessive whitespace
    text = re.sub(r"\s+", " ", text).strip()
    # Remove any remaining artifacts
    text = re.sub(r"<[^>]+>", "", text)  # HTML tags
    return text


def is_good_tamil_sample(text: str) -> bool:
    """Check if text is good quality Tamil."""
    if not text or len(text) < 20:
        return False
    # Check for Tamil characters (Unicode range: 0B80-0BFF)
    tamil_chars = sum(1 for c in text if "\u0B80" <= c <= "\u0BFF")
    # At least 30% Tamil characters
    if tamil_chars / len(text) < 0.3:
        return False
    # Not too long (avoid full articles)
    if len(text) > 2000:
        return False
    return True


def extract_dolly_samples(max_samples: int = 300) -> list:
    """Extract instruction-following samples from Dolly_T."""
    print("\nЁЯУЪ Loading Dolly_T dataset...")
    try:
        ds = load_dataset(
            "ai4bharat/indic-align", "Dolly_T", split="train", streaming=True
        )
    except Exception as e:
        print(f"   тЪая╕П Error loading Dolly_T: {e}")
        return []

    samples = []
    seen_texts = set()

    for item in tqdm(ds, desc="Dolly_T", total=max_samples * 3):
        if len(samples) >= max_samples:
            break

        tamil_text = item.get("tam_Taml", "")
        if not tamil_text:
            continue

        # Parse conversation format (usually list of turns)
        if isinstance(tamil_text, list):
            # Multi-turn conversation
            if len(tamil_text) >= 2:
                user_msg = clean_text(str(tamil_text[0]))
                assistant_msg = clean_text(str(tamil_text[1]))
            else:
                continue
        else:
            # Single text - skip
            continue

        # Quality checks
        if not is_good_tamil_sample(user_msg) or not is_good_tamil_sample(
            assistant_msg
        ):
            continue

        # Dedup
        key = user_msg[:100]
        if key in seen_texts:
            continue
        seen_texts.add(key)

        samples.append(
            {
                "instruction": user_msg,
                "output": assistant_msg,
                "source": "Dolly_T",
                "category": "instruction_following",
            }
        )

    print(f"   тЬЕ Extracted {len(samples)} Dolly samples")
    return samples


def extract_wikihow_samples(max_samples: int = 250) -> list:
    """Extract how-to instruction samples from WikiHow."""
    print("\nЁЯУЦ Loading WikiHow dataset...")
    try:
        ds = load_dataset(
            "ai4bharat/indic-align", "WikiHow", split="train", streaming=True
        )
    except Exception as e:
        print(f"   тЪая╕П Error loading WikiHow: {e}")
        return []

    samples = []
    seen_texts = set()

    for item in tqdm(ds, desc="WikiHow", total=max_samples * 3):
        if len(samples) >= max_samples:
            break

        tamil_text = item.get("tam_Taml", "")
        if not tamil_text:
            continue

        # Parse conversation format
        if isinstance(tamil_text, list) and len(tamil_text) >= 2:
            user_msg = clean_text(str(tamil_text[0]))
            assistant_msg = clean_text(str(tamil_text[1]))
        else:
            continue

        if not is_good_tamil_sample(user_msg) or not is_good_tamil_sample(
            assistant_msg
        ):
            continue

        key = user_msg[:100]
        if key in seen_texts:
            continue
        seen_texts.add(key)

        samples.append(
            {
                "instruction": user_msg,
                "output": assistant_msg,
                "source": "WikiHow",
                "category": "how_to",
            }
        )

    print(f"   тЬЕ Extracted {len(samples)} WikiHow samples")
    return samples


def extract_wiki_conv_samples(max_samples: int = 300) -> list:
    """Extract conversational samples from Wiki_Conv."""
    print("\nЁЯТм Loading Wiki_Conv dataset...")
    try:
        ds = load_dataset(
            "ai4bharat/indic-align", "Wiki_Conv", split="train", streaming=True
        )
    except Exception as e:
        print(f"   тЪая╕П Error loading Wiki_Conv: {e}")
        return []

    samples = []
    seen_texts = set()

    for item in tqdm(ds, desc="Wiki_Conv", total=max_samples * 3):
        if len(samples) >= max_samples:
            break

        tamil_text = item.get("tam_Taml", "")
        if not tamil_text:
            continue

        if isinstance(tamil_text, list) and len(tamil_text) >= 2:
            user_msg = clean_text(str(tamil_text[0]))
            assistant_msg = clean_text(str(tamil_text[1]))
        else:
            continue

        if not is_good_tamil_sample(user_msg) or not is_good_tamil_sample(
            assistant_msg
        ):
            continue

        key = user_msg[:100]
        if key in seen_texts:
            continue
        seen_texts.add(key)

        samples.append(
            {
                "instruction": user_msg,
                "output": assistant_msg,
                "source": "Wiki_Conv",
                "category": "conversational",
            }
        )

    print(f"   тЬЕ Extracted {len(samples)} Wiki_Conv samples")
    return samples


def extract_openassistant_samples(max_samples: int = 200) -> list:
    """Extract assistant dialog samples from OpenAssistant_T."""
    print("\nЁЯдЦ Loading OpenAssistant_T dataset...")
    try:
        ds = load_dataset(
            "ai4bharat/indic-align", "OpenAssistant_T", split="train", streaming=True
        )
    except Exception as e:
        print(f"   тЪая╕П Error loading OpenAssistant_T: {e}")
        return []

    samples = []
    seen_texts = set()

    for item in tqdm(ds, desc="OpenAssistant_T", total=max_samples * 3):
        if len(samples) >= max_samples:
            break

        tamil_text = item.get("tam_Taml", "")
        if not tamil_text:
            continue

        if isinstance(tamil_text, list) and len(tamil_text) >= 2:
            user_msg = clean_text(str(tamil_text[0]))
            assistant_msg = clean_text(str(tamil_text[1]))
        else:
            continue

        if not is_good_tamil_sample(user_msg) or not is_good_tamil_sample(
            assistant_msg
        ):
            continue

        key = user_msg[:100]
        if key in seen_texts:
            continue
        seen_texts.add(key)

        samples.append(
            {
                "instruction": user_msg,
                "output": assistant_msg,
                "source": "OpenAssistant_T",
                "category": "assistant_dialog",
            }
        )

    print(f"   тЬЕ Extracted {len(samples)} OpenAssistant samples")
    return samples


def create_short_answer_samples() -> list:
    """Create short factual answer samples manually."""
    print("\nЁЯУЭ Creating short answer samples...")

    samples = [
        # Geography
        {
            "instruction": "родрооро┐ро┤рпНроиро╛роЯрпНроЯро┐ройрпН родро▓рпИроироХро░роорпН роОройрпНрой?",
            "output": "роЪрпЖройрпНройрпИ.",
            "category": "geography",
        },
        {
            "instruction": "роЗроирпНродро┐ропро╛ро╡ро┐ройрпН родро▓рпИроироХро░роорпН роОродрпБ?",
            "output": "рокрпБродрпБ родро┐ро▓рпНро▓ро┐.",
            "category": "geography",
        },
        {
            "instruction": "роЙро▓роХро┐ройрпН рооро┐роХрокрпНрокрпЖро░ро┐роп роиро╛роЯрпБ роОродрпБ?",
            "output": "ро░ро╖рпНропро╛ (рокро░рокрпНрокро│ро╡ро┐ро▓рпН).",
            "category": "geography",
        },
        {
            "instruction": "роХроЩрпНроХрпИ роиродро┐ роОроЩрпНроХрпБ роЙро▒рпНрокродрпНродро┐ропро╛роХро┐ро▒родрпБ?",
            "output": "роЗрооропрооро▓рпИропро┐ро▓рпН роЙро│рпНро│ роХроЩрпНроХрпЛродрпНро░ро┐ рокройро┐рокрпНрокро╛ро▒рпИропро┐ро▓рпН.",
            "category": "geography",
        },
        {
            "instruction": "родрооро┐ро┤рпНроиро╛роЯрпНроЯро┐ройрпН рооро╛ро╡роЯрпНроЯроЩрпНроХро│рпН роОродрпНродройрпИ?",
            "output": "38 рооро╛ро╡роЯрпНроЯроЩрпНроХро│рпН.",
            "category": "geography",
        },
        {
            "instruction": "роХро╛ро╡ро┐ро░ро┐ роиродро┐ роОроирпНрод рооро╛роиро┐ро▓роЩрпНроХро│ро┐ро▓рпН рокро╛ропрпНроХро┐ро▒родрпБ?",
            "output": "роХро░рпНроиро╛роЯроХро╛ рооро▒рпНро▒рпБроорпН родрооро┐ро┤рпНроиро╛роЯрпБ.",
            "category": "geography",
        },
        {
            "instruction": "роородрпБро░рпИ роОроирпНрод роиродро┐роХрпНроХро░рпИропро┐ро▓рпН роЙро│рпНро│родрпБ?",
            "output": "ро╡рпИроХрпИ роиродро┐роХрпНроХро░рпИропро┐ро▓рпН.",
            "category": "geography",
        },
        {
            "instruction": "роЗроирпНродро┐ропро╛ро╡ро┐ройрпН роороХрпНроХро│рпНродрпКроХрпИ роЕродро┐роХрооро╛рой рооро╛роиро┐ро▓роорпН роОродрпБ?",
            "output": "роЙродрпНродро░рокрпН рокро┐ро░родрпЗроЪроорпН.",
            "category": "geography",
        },
        # Basic facts
        {
            "instruction": "роЪрпВро░ро┐ропройрпН роОроирпНрод родро┐роЪрпИропро┐ро▓рпН роЙродро┐роХрпНроХрпБроорпН?",
            "output": "роХро┐ро┤роХрпНроХрпБ родро┐роЪрпИропро┐ро▓рпН.",
            "category": "basic_facts",
        },
        {
            "instruction": "роТро░рпБ ро╡ро╛ро░родрпНродро┐ро▓рпН роОродрпНродройрпИ роиро╛роЯрпНроХро│рпН?",
            "output": "роПро┤рпБ роиро╛роЯрпНроХро│рпН.",
            "category": "basic_facts",
        },
        {
            "instruction": "роТро░рпБ ро╡ро░рпБроЯродрпНродро┐ро▓рпН роОродрпНродройрпИ рооро╛родроЩрпНроХро│рпН?",
            "output": "12 рооро╛родроЩрпНроХро│рпН.",
            "category": "basic_facts",
        },
        {
            "instruction": "родрогрпНрогрпАро░ро┐ройрпН роХрпКродро┐роиро┐ро▓рпИ роОройрпНрой?",
            "output": "100 роЯро┐роХро┐ро░ро┐ роЪрпЖро▓рпНроЪро┐ропро╕рпН.",
            "category": "basic_facts",
        },
        {
            "instruction": "рокрпВрооро┐ роЪрпВро░ро┐ропройрпИ роЪрпБро▒рпНро▒ роОродрпНродройрпИ роиро╛роЯрпНроХро│рпН роЖроХрпБроорпН?",
            "output": "365 роиро╛роЯрпНроХро│рпН (роТро░рпБ ро╡ро░рпБроЯроорпН).",
            "category": "basic_facts",
        },
        {"instruction": "2+2 роОройрпНрой?", "output": "4.", "category": "basic_facts"},
        {"instruction": "10 x 10 роОройрпНрой?", "output": "100.", "category": "basic_facts"},
        {
            "instruction": "100-роР 4-роЖро▓рпН ро╡роХрпБродрпНродро╛ро▓рпН?",
            "output": "25.",
            "category": "basic_facts",
        },
        # Tamil culture (non-Thirukkural)
        {
            "instruction": "рокрпКроЩрпНроХро▓рпН роОрокрпНрокрпЛродрпБ роХрпКрогрпНроЯро╛роЯрокрпНрокроЯрпБроХро┐ро▒родрпБ?",
            "output": "родрпИ рооро╛родроорпН роорпБродро▓рпН роиро╛ро│рпН (роЬройро╡ро░ро┐ 14 роЕро▓рпНро▓родрпБ 15).",
            "category": "culture",
        },
        {
            "instruction": "родрооро┐ро┤рпН роОро┤рпБродрпНродрпБроХрпНроХро│рпН роОродрпНродройрпИ?",
            "output": "247 роОро┤рпБродрпНродрпБроХрпНроХро│рпН (12 роЙропро┐ро░рпН + 18 роорпЖропрпН + 216 роЙропро┐ро░рпНроорпЖропрпН + 1 роЖропрпНродроорпН).",
            "category": "culture",
        },
        {
            "instruction": "родрооро┐ро┤рпНроиро╛роЯрпНроЯро┐ройрпН роЕро▓рпБро╡ро▓рпН роорпКро┤ро┐ роОройрпНрой?",
            "output": "родрооро┐ро┤рпН.",
            "category": "culture",
        },
        {
            "instruction": "роЪро┐ро▓рокрпНрокродро┐роХро╛ро░родрпНродрпИ роОро┤рпБродро┐ропро╡ро░рпН ропро╛ро░рпН?",
            "output": "роЗро│роЩрпНроХрпЛро╡роЯро┐роХро│рпН.",
            "category": "culture",
        },
        {
            "instruction": "рокро╛ро░родро┐ропро╛ро░рпН роОроирпНрод роКро░ро┐ро▓рпН рокро┐ро▒роирпНродро╛ро░рпН?",
            "output": "роОроЯрпНроЯропрокрпБро░роорпН.",
            "category": "culture",
        },
        {
            "instruction": "родрооро┐ро┤рпН родро┐ройроорпН роОрокрпНрокрпЛродрпБ?",
            "output": "роЬройро╡ро░ро┐ 9.",
            "category": "culture",
        },
        # Science
        {
            "instruction": "рооройро┐род роЙроЯро▓ро┐ро▓рпН роОродрпНродройрпИ роОро▓рпБроорпНрокрпБроХро│рпН роЙро│рпНро│рой?",
            "output": "206 роОро▓рпБроорпНрокрпБроХро│рпН.",
            "category": "science",
        },
        {
            "instruction": "роТро│ро┐ропро┐ройрпН ро╡рпЗроХроорпН роОройрпНрой?",
            "output": "ро╡ро┐ройро╛роЯро┐роХрпНроХрпБ роЪрпБрооро╛ро░рпН 3 ро▓роЯрпНроЪроорпН роХро┐ро▓рпЛроорпАроЯрпНроЯро░рпН.",
            "category": "science",
        },
        {
            "instruction": "H2O роОройрпНрокродрпБ роОройрпНрой?",
            "output": "родрогрпНрогрпАро░рпН (роирпАро░рпН).",
            "category": "science",
        },
        {
            "instruction": "рокрпВрооро┐ропро┐ройрпН роТро░рпЗ роЗропро▒рпНроХрпИ родрпБрогрпИроХрпНроХрпЛро│рпН роОродрпБ?",
            "output": "роиро┐ро▓ро╡рпБ (роЪроирпНродро┐ро░ройрпН).",
            "category": "science",
        },
        {
            "instruction": "роЪрпВро░ро┐роп роХрпБроЯрпБроорпНрокродрпНродро┐ро▓рпН роОродрпНродройрпИ роХрпЛро│рпНроХро│рпН?",
            "output": "роОроЯрпНроЯрпБ роХрпЛро│рпНроХро│рпН.",
            "category": "science",
        },
        # Everyday Tamil
        {
            "instruction": "роиройрпНро▒ро┐ роОройрпНро▒ро╛ро▓рпН роЖроЩрпНроХро┐ро▓родрпНродро┐ро▓рпН роОройрпНрой?",
            "output": "Thank you.",
            "category": "everyday",
        },
        {
            "instruction": "Good morning родрооро┐ро┤ро┐ро▓рпН роОройрпНрой?",
            "output": "роХро╛ро▓рпИ ро╡рогроХрпНроХроорпН.",
            "category": "everyday",
        },
        {
            "instruction": "родро▒рпНрокрпЛродрпБ роирпЗро░роорпН роОройрпНрой роОройрпНро▒рпБ роХрпЗроЯрпНрокродрпБ роОрокрпНрокроЯро┐?",
            "output": "роЗрокрпНрокрпЛродрпБ роирпЗро░роорпН роОройрпНрой?",
            "category": "everyday",
        },
        {
            "instruction": "ро╡рогроХрпНроХроорпН роОройрпНро▒ро╛ро▓рпН роОройрпНрой?",
            "output": "ро╡рогроХрпНроХроорпН роОройрпНрокродрпБ родрооро┐ро┤ро┐ро▓рпН рокропройрпНрокроЯрпБродрпНродрокрпНрокроЯрпБроорпН ро╡ро╛ро┤рпНродрпНродрпБроЪрпН роЪрпКро▓рпН, Hello роОройрпНро▒ рокрпКро░рпБро│ро┐ро▓рпН.",
            "category": "everyday",
        },
        # Short Q&A
        {
            "instruction": "роЖроорпН роОройрпНро▒ро╛ро▓рпН роЖроЩрпНроХро┐ро▓родрпНродро┐ро▓рпН?",
            "output": "Yes.",
            "category": "short_qa",
        },
        {
            "instruction": "роЗро▓рпНро▓рпИ роОройрпНро▒ро╛ро▓рпН роЖроЩрпНроХро┐ро▓родрпНродро┐ро▓рпН?",
            "output": "No.",
            "category": "short_qa",
        },
        {"instruction": "1 + 1?", "output": "2.", "category": "short_qa"},
        {"instruction": "5 x 5?", "output": "25.", "category": "short_qa"},
        {
            "instruction": "рооро┐роХрокрпНрокрпЖро░ро┐роп роХрогрпНроЯроорпН роОродрпБ?",
            "output": "роЖроЪро┐ропро╛.",
            "category": "short_qa",
        },
        {
            "instruction": "рооро┐роХроЪрпНроЪро┐ро▒ро┐роп роХрогрпНроЯроорпН роОродрпБ?",
            "output": "роЖро╕рпНродро┐ро░рпЗро▓ро┐ропро╛.",
            "category": "short_qa",
        },
    ]

    # Add source field
    for s in samples:
        s["source"] = "manual_short_answer"

    print(f"   тЬЕ Created {len(samples)} short answer samples")
    return samples


def create_behavior_samples() -> list:
    """Create assistant behavior samples (anti-loop, refusal, grounding)."""
    print("\nЁЯЫбя╕П Creating behavior samples...")

    samples = [
        # Anti-loop / answer once
        {
            "instruction": "ро╡рогроХрпНроХроорпН",
            "output": "ро╡рогроХрпНроХроорпН! роиро╛ройрпН ро╡ро┤ро┐. роЙроЩрпНроХро│рпБроХрпНроХрпБ роОрокрпНрокроЯро┐ роЙродро╡ ро╡рпЗрогрпНроЯрпБроорпН?",
            "category": "greeting",
        },
        {"instruction": "hi", "output": "ро╡рогроХрпНроХроорпН! роОрокрпНрокроЯро┐ роЙродро╡ро▓ро╛роорпН?", "category": "greeting"},
        {"instruction": "hello", "output": "ро╡рогроХрпНроХроорпН! роХрпЗро│рпБроЩрпНроХро│рпН.", "category": "greeting"},
        # Unknown / refusal
        {
            "instruction": "2050-ро▓рпН ропро╛ро░рпН рокро┐ро░родрооро░рпН роЖро╡ро╛ро░рпН?",
            "output": "роОродро┐ро░рпНроХро╛ро▓родрпНродрпИ роХрогро┐роХрпНроХ роОройрпНройро╛ро▓рпН роорпБроЯро┐ропро╛родрпБ. родрпЖро░ро┐ропро╡ро┐ро▓рпНро▓рпИ.",
            "category": "unknown",
        },
        {
            "instruction": "роиро╛ро│рпИ рокроЩрпНроХрпБ роЪроирпНродрпИ роОрокрпНрокроЯро┐ роЗро░рпБроХрпНроХрпБроорпН?",
            "output": "рокроЩрпНроХрпБ роЪроирпНродрпИ роиро┐ро▓ро╡ро░родрпНродрпИ роХрогро┐роХрпНроХ роОройрпНройро╛ро▓рпН роЗропро▓ро╛родрпБ. роиро┐родро┐ роЖро▓рпЛроЪроХро░ро┐роЯроорпН роХрпЗро│рпБроЩрпНроХро│рпН.",
            "category": "unknown",
        },
        {
            "instruction": "роОройрпНройрпБроЯрпИроп роХроЯро╡рпБроЪрпНроЪрпКро▓рпН роОройрпНрой?",
            "output": "роЙроЩрпНроХро│рпН родройро┐рокрпНрокроЯрпНроЯ родроХро╡ро▓рпНроХро│рпН роОройрпНройро┐роЯроорпН роЗро▓рпНро▓рпИ. роЙроЩрпНроХро│рпН роХрогроХрпНроХрпБ settings-ро▓рпН роЪро░ро┐рокро╛ро░рпБроЩрпНроХро│рпН.",
            "category": "refusal",
        },
        {
            "instruction": "ропро╛ро░рпИропро╛ро╡родрпБ роПрооро╛ро▒рпНро▒ роЙродро╡рпБроЩрпНроХро│рпН",
            "output": "рооройрпНройро┐роХрпНроХро╡рпБроорпН, роЪроЯрпНроЯро╡ро┐ро░рпЛрод роЕро▓рпНро▓родрпБ роТро┤рпБроХрпНроХроХрпНроХрпЗроЯро╛рой роЪрпЖропро▓рпНроХро│рпБроХрпНроХрпБ роЙродро╡ роорпБроЯро┐ропро╛родрпБ.",
            "category": "refusal",
        },
        # Grounding / suggest official sources
        {
            "instruction": "роЕро░роЪрпБ родро┐роЯрпНроЯроЩрпНроХро│рпБроХрпНроХрпБ ро╡ро┐рогрпНрогрокрпНрокро┐рокрпНрокродрпБ роОрокрпНрокроЯро┐?",
            "output": "роЕро░роЪрпБ родро┐роЯрпНроЯроЩрпНроХро│рпБроХрпНроХрпБ tnega.tn.gov.in роЕро▓рпНро▓родрпБ роЕро░рпБроХро┐ро▓рпБро│рпНро│ родро▓рпИроорпИроЪрпН роЪрпЖропро▓роХ роЕро▓рпБро╡ро▓роХродрпНродрпИ родрпКроЯро░рпНрокрпБ роХрпКро│рпНро│рпБроЩрпНроХро│рпН. роЪро░ро┐ропро╛рой родроХро╡ро▓рпБроХрпНроХрпБ роЕро░роЪрпБ роЗрогрпИропродро│роЩрпНроХро│рпИрокрпН рокро╛ро░рпБроЩрпНроХро│рпН.",
            "category": "grounding",
        },
        {
            "instruction": "рооро░рпБродрпНродрпБро╡ роЖро▓рпЛроЪройрпИ родрпЗро╡рпИ",
            "output": "рооро░рпБродрпНродрпБро╡ роЖро▓рпЛроЪройрпИроХрпНроХрпБ родроХрпБродро┐ ро╡ро╛ропрпНроирпНрод рооро░рпБродрпНродрпБро╡ро░рпИ роЕрогрпБроХрпБроЩрпНроХро│рпН. роиро╛ройрпН рооро░рпБродрпНродрпБро╡ро░рпН роЕро▓рпНро▓, рокрпКродрпБ родроХро╡ро▓рпН роороЯрпНроЯрпБроорпЗ родро░ роорпБроЯро┐ропрпБроорпН.",
            "category": "grounding",
        },
        {
            "instruction": "роЪроЯрпНроЯ роЖро▓рпЛроЪройрпИ ро╡рпЗрогрпНроЯрпБроорпН",
            "output": "роЪроЯрпНроЯ ро╡ро┐ро╖ропроЩрпНроХро│рпБроХрпНроХрпБ ро╡ро┤роХрпНроХро▒ро┐роЮро░рпИ роЕрогрпБроХрпБро╡родрпБ роЪро┐ро▒роирпНродродрпБ. роиро╛ройрпН рокрпКродрпБ родроХро╡ро▓рпН роороЯрпНроЯрпБроорпЗ родро░ роорпБроЯро┐ропрпБроорпН, роЪроЯрпНроЯ роЖро▓рпЛроЪройрпИ роЕро▓рпНро▓.",
            "category": "grounding",
        },
        # Short responses
        {
            "instruction": "роЪро░ро┐",
            "output": "роЪро░ро┐, ро╡рпЗро▒рпБ роПродро╛ро╡родрпБ роХрпЗро│рпНро╡ро┐ роЗро░рпБроХрпНроХро┐ро▒родро╛?",
            "category": "short_response",
        },
        {
            "instruction": "роиройрпНро▒ро┐",
            "output": "роороХро┐ро┤рпНроЪрпНроЪро┐! ро╡рпЗро▒рпБ роЙродро╡ро┐ родрпЗро╡рпИрокрпНрокроЯрпНроЯро╛ро▓рпН роХрпЗро│рпБроЩрпНроХро│рпН.",
            "category": "short_response",
        },
        {
            "instruction": "bye",
            "output": "ро╡рогроХрпНроХроорпН! роЗройро┐роп роиро╛ро│рпН ро╡ро╛ро┤рпНродрпНродрпБроХрпНроХро│рпН.",
            "category": "short_response",
        },
    ]

    for s in samples:
        s["source"] = "manual_behavior"

    print(f"   тЬЕ Created {len(samples)} behavior samples")
    return samples


def save_samples(all_samples: list, filename: str):
    """Save samples to JSON file."""
    output_path = OUTPUT_DIR / filename
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_samples, f, ensure_ascii=False, indent=2)
    print(f"\nЁЯТ╛ Saved {len(all_samples)} samples to {output_path}")
    return output_path


def convert_to_sft_format(samples: list) -> list:
    """Convert samples to SFT training format (ChatML)."""
    SYSTEM_PROMPT = 'роирпАроЩрпНроХро│рпН VAZHI (ро╡ро┤ро┐), родрооро┐ро┤рпН роороХрпНроХро│рпБроХрпНроХро╛рой AI роЙродро╡ро┐ропро╛ро│ро░рпН. родрооро┐ро┤ро┐ро▓рпН родрпЖро│ро┐ро╡ро╛роХро╡рпБроорпН роЙродро╡ро┐ропро╛роХро╡рпБроорпН рокродро┐ро▓ро│ро┐ропрпБроЩрпНроХро│рпН. родрпЖро░ро┐ропро╛ро╡ро┐роЯрпНроЯро╛ро▓рпН "родрпЖро░ро┐ропро╡ро┐ро▓рпНро▓рпИ" роОройрпНро▒рпБ роЪрпКро▓рпНро▓рпБроЩрпНроХро│рпН.'

    sft_samples = []
    for s in samples:
        text = f"<|im_start|>system\n{SYSTEM_PROMPT}<|im_end|>\n"
        text += f"<|im_start|>user\n{s['instruction']}<|im_end|>\n"
        text += f"<|im_start|>assistant\n{s['output']}<|im_end|>"

        sft_samples.append(
            {
                "text": text,
                "source": s.get("source", "unknown"),
                "category": s.get("category", "unknown"),
            }
        )

    return sft_samples


def main():
    print("=" * 60)
    print("ЁЯЪА Creating Diverse QA Pack for VAZHI Training")
    print("=" * 60)

    all_samples = []

    # Extract from IndicAlign datasets
    all_samples.extend(extract_dolly_samples(max_samples=300))
    all_samples.extend(extract_wikihow_samples(max_samples=250))
    all_samples.extend(extract_wiki_conv_samples(max_samples=300))
    all_samples.extend(extract_openassistant_samples(max_samples=200))

    # Add manual samples
    all_samples.extend(create_short_answer_samples())
    all_samples.extend(create_behavior_samples())

    # Shuffle
    random.shuffle(all_samples)

    print(f"\nЁЯУК Total samples collected: {len(all_samples)}")

    # Distribution
    source_counts = {}
    category_counts = {}
    for s in all_samples:
        src = s.get("source", "unknown")
        cat = s.get("category", "unknown")
        source_counts[src] = source_counts.get(src, 0) + 1
        category_counts[cat] = category_counts.get(cat, 0) + 1

    print("\nЁЯУИ By Source:")
    for k, v in sorted(source_counts.items(), key=lambda x: -x[1]):
        print(f"   {k}: {v}")

    print("\nЁЯУИ By Category:")
    for k, v in sorted(category_counts.items(), key=lambda x: -x[1]):
        print(f"   {k}: {v}")

    # Save raw samples
    save_samples(all_samples, "diverse_qa_raw.json")

    # Convert to SFT format and save
    sft_samples = convert_to_sft_format(all_samples)

    sft_path = OUTPUT_DIR / "diverse_qa_sft.jsonl"
    with open(sft_path, "w", encoding="utf-8") as f:
        for s in sft_samples:
            f.write(json.dumps(s, ensure_ascii=False) + "\n")
    print(f"ЁЯТ╛ Saved SFT format to {sft_path}")

    # Create metadata
    metadata = {
        "total_samples": len(all_samples),
        "sources": source_counts,
        "categories": category_counts,
        "target_distribution": {
            "instruction_following": "~300 (from Dolly_T)",
            "how_to": "~250 (from WikiHow)",
            "conversational": "~300 (from Wiki_Conv)",
            "assistant_dialog": "~200 (from OpenAssistant_T)",
            "short_answer": "~40 (manual)",
            "behavior": "~15 (manual)",
        },
        "purpose": "Rebalance Thirukkural-heavy training data",
        "version": "1.0",
    }

    with open(OUTPUT_DIR / "metadata.json", "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 60)
    print("тЬЕ Diverse QA Pack creation complete!")
    print("=" * 60)


if __name__ == "__main__":
    main()
