{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# VAZHI v0.4 - High-Tamil LoRA Training\n\n**Key improvements over v0.2:**\n- 86.7% Tamil content (vs 2.6% in original data)\n- Fixed formatting function (batch-compatible)\n- Tamil-first bilingual format\n- 512 max tokens for inference\n- Standardized data format\n- Content-deduplicated (0 duplicates)\n\n**Training Data:**\n- Train: 2,732 samples\n- Val: 301 samples\n- Total: 3,033 unique samples\n\n**Pack Distribution (balanced across all 6 domains):**\n- vazhi_panpaadu (Culture): 625 samples\n- vazhi_sattam (Legal): 590 samples\n- vazhi_kaval (Security): 467 samples\n- vazhi_maruthuvam (Healthcare): 462 samples\n- vazhi_arasu (Government): 452 samples\n- vazhi_kalvi (Education): 437 samples\n\n**Data Location:** `data/v04/training/`\n\n**Run on GPU runtime (T4 or A100)**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install unsloth\n",
    "!pip install --no-deps trl peft accelerate bitsandbytes\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training data\n",
    "from google.colab import files\n",
    "print(\"Upload vazhi_v04_train.json and vazhi_v04_val.json\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verify\n",
    "import os\n",
    "for f in os.listdir('.'):\n",
    "    if f.endswith('.json'):\n",
    "        print(f\"  - {f} ({os.path.getsize(f) / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with Unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded! Parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"LoRA configured! Trainable: {model.num_parameters(only_trainable=True):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAZHI v0.4 Tamil-first system prompt\n",
    "SYSTEM_PROMPT = \"\"\"நீங்கள் வழி (VAZHI), தமிழ்நாடு மக்களுக்கான AI உதவியாளர். தமிழில் தெளிவாகவும் உதவியாகவும் பதிலளியுங்கள். தொழில்நுட்ப சொற்களை தமிழில் முதலில் கூறி, பிறகு ஆங்கிலத்தில் அடைப்புக்குறிக்குள் குறிப்பிடுங்கள்.\"\"\"\n",
    "\n",
    "# Fixed formatting function - handles both single and batched examples\n",
    "def format_prompt(examples):\n",
    "    \"\"\"Format training examples into Qwen chat template. Returns list.\"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    # Handle both single example and batch\n",
    "    if isinstance(examples['instruction'], list):\n",
    "        # Batched\n",
    "        for instruction, output in zip(examples['instruction'], examples['output']):\n",
    "            text = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{instruction}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{output}<|im_end|>\"\"\"\n",
    "            texts.append(text)\n",
    "    else:\n",
    "        # Single example\n",
    "        text = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{examples['instruction']}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{examples['output']}<|im_end|>\"\"\"\n",
    "        texts.append(text)\n",
    "    \n",
    "    return texts\n",
    "\n",
    "print(\"Formatting function configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "with open(\"vazhi_v04_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"vazhi_v04_val.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "\n",
    "print(f\"Training: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(val_dataset)} samples\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample instruction: {train_dataset[0]['instruction'][:80]}...\")\n",
    "print(f\"Sample pack: {train_dataset[0]['pack']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Tamil content in data\n",
    "import re\n",
    "\n",
    "def tamil_pct(text):\n",
    "    if not text: return 0\n",
    "    tamil = len(re.findall(r'[\\u0B80-\\u0BFF]', text))\n",
    "    total = len(re.findall(r'[\\u0B80-\\u0BFF\\w]', text))\n",
    "    return (tamil / total * 100) if total > 0 else 0\n",
    "\n",
    "# Check first 100 samples\n",
    "pcts = [tamil_pct(s['output']) for s in train_data[:100]]\n",
    "print(f\"Average Tamil %: {sum(pcts)/len(pcts):.1f}%\")\n",
    "print(f\"Min Tamil %: {min(pcts):.1f}%\")\n",
    "print(f\"Max Tamil %: {max(pcts):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vazhi-v04-lora\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,  # Effective batch size = 8\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=50,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    seed=42,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    formatting_func=format_prompt,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(train_dataset) // 8\n",
    "print(f\"Ready! Batch size: 8 | Steps/epoch: {steps_per_epoch} | Total steps: {steps_per_epoch * 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "import time\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"VAZHI v0.4 Training Starting!\")\n",
    "print(f\"Training {len(train_dataset)} high-Tamil samples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Training Complete! Time: {elapsed/60:.1f} minutes\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained(\"vazhi-v04-lora-final\")\n",
    "tokenizer.save_pretrained(\"vazhi-v04-lora-final\")\n",
    "\n",
    "# Download\n",
    "import shutil\n",
    "shutil.make_archive(\"vazhi-v04-lora-final\", 'zip', \"vazhi-v04-lora-final\")\n",
    "files.download(\"vazhi-v04-lora-final.zip\")\n",
    "print(\"Model saved and downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model - improved parsing from v0.2\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def vazhi_chat(user_message, max_tokens=512):\n",
    "    \"\"\"Chat with VAZHI v0.4 model.\"\"\"\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{SYSTEM_PROMPT}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_message}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Extract assistant response (improved parsing)\n",
    "    if \"<|im_start|>assistant\" in response:\n",
    "        response = response.split(\"<|im_start|>assistant\")[-1]\n",
    "    \n",
    "    # Clean up markers\n",
    "    response = response.replace(\"<|im_end|>\", \"\").strip()\n",
    "    response = response.replace(\"<|im_start|>\", \"\").strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"Inference function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive test across all packs\n",
    "tests = [\n",
    "    (\"Culture\", \"திருக்குறளின் முதல் குறள் என்ன?\"),\n",
    "    (\"Culture\", \"சித்தர்கள் யார்?\"),\n",
    "    (\"Security\", \"மோசடி செய்தியை எப்படி கண்டறிவது?\"),\n",
    "    (\"Government\", \"முதலமைச்சர் காப்பீட்டு அட்டை எப்படி பெறுவது?\"),\n",
    "    (\"Education\", \"நீட் தேர்வுக்கு எப்படி தயாராவது?\"),\n",
    "    (\"Legal\", \"தகவல் அறியும் உரிமைச் சட்டம் என்றால் என்ன?\"),\n",
    "    (\"Healthcare\", \"அரசு மருத்துவமனையில் இலவச சிகிச்சை கிடைக்குமா?\"),\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VAZHI v0.4 - High Tamil Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, q in tests:\n",
    "    print(f\"\\n[{category}] Q: {q}\")\n",
    "    response = vazhi_chat(q)\n",
    "    # Check Tamil %\n",
    "    pct = tamil_pct(response)\n",
    "    print(f\"A: {response[:300]}...\" if len(response) > 300 else f\"A: {response}\")\n",
    "    print(f\"Tamil %: {pct:.1f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# v0.4 Summary\nprint(\"\"\"\n╔══════════════════════════════════════════════════════════════╗\n║              VAZHI v0.4 Training Complete!                   ║\n╠══════════════════════════════════════════════════════════════╣\n║  Key improvements:                                           ║\n║  ┌─────────────────────┬───────────┬───────────┐             ║\n║  │ Feature             │ v0.2      │ v0.4      │             ║\n║  ├─────────────────────┼───────────┼───────────┤             ║\n║  │ Tamil content       │ ~2.6%     │ 86.7%     │             ║\n║  │ Training samples    │ 2,860*    │ 3,033     │             ║\n║  │ Bilingual format    │ Mixed     │ Tamil 1st │             ║\n║  │ Tanglish            │ Heavy     │ Minimal   │             ║\n║  │ Data format         │ Mixed     │ Standard  │             ║\n║  │ Duplicates          │ 320       │ 0         │             ║\n║  └─────────────────────┴───────────┴───────────┘             ║\n║  * v0.2 reported 3,180 but had 320 duplicate IDs             ║\n║                                                              ║\n║  Pack Distribution (all standardized as vazhi_*):            ║\n║  - vazhi_panpaadu (Culture): 625 samples                     ║\n║  - vazhi_sattam (Legal): 590 samples                         ║\n║  - vazhi_kaval (Security): 467 samples                       ║\n║  - vazhi_maruthuvam (Healthcare): 462 samples                ║\n║  - vazhi_arasu (Government): 452 samples                     ║\n║  - vazhi_kalvi (Education): 437 samples                      ║\n║                                                              ║\n║  Files saved: vazhi-v04-lora-final.zip                       ║\n╚══════════════════════════════════════════════════════════════╝\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Push to HuggingFace Hub\n",
    "# Uncomment to upload\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login()  # Enter your token\n",
    "# \n",
    "# model.push_to_hub(\"cryptoyogillc/vazhi-tamil-v04\")\n",
    "# tokenizer.push_to_hub(\"cryptoyogillc/vazhi-tamil-v04\")\n",
    "# print(\"Uploaded to HuggingFace Hub!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}